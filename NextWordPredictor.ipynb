{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p7fzOzEFJs47",
        "outputId": "f1b9104f-a4d1-4efe-be6f-80582e502c29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Starting Training ---\n",
            "Epoch 20/100 | Loss: 0.0135\n",
            "Epoch 40/100 | Loss: 0.0009\n",
            "Epoch 60/100 | Loss: 0.0005\n",
            "Epoch 80/100 | Loss: 0.0004\n",
            "Epoch 100/100 | Loss: 0.0003\n",
            "\n",
            "--- Testing Model ---\n",
            "Input: 'What is'\n",
            "Output: 'What is python? python is a popular programming language used for data science. data science involves statistics, programming, and machine learning. machine'\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# 1. SAMPLE DATA\n",
        "data = \"\"\"\n",
        "What is Python? Python is a popular programming language used for data science.\n",
        "Data science involves statistics, programming, and machine learning.\n",
        "Machine learning is a subset of artificial intelligence.\n",
        "Artificial intelligence aims to create smart machines.\n",
        "How to learn data science? You should start by learning Python and libraries like Numpy.\n",
        "Numpy is used for numerical computing in Python.\n",
        "Pandas is a great tool for data manipulation and analysis.\n",
        "Machine learning models require clean data for training.\n",
        "Deep learning uses neural networks like LSTM for sequence prediction.\n",
        "LSTMs are great for natural language processing tasks.\n",
        "Natural language processing helps computers understand human text.\n",
        "The course covers deep learning and neural networks in detail.\n",
        "You will build projects using PyTorch and Scikit-Learn.\n",
        "PyTorch is a flexible deep learning framework developed by Meta.\n",
        "Keep practicing to master the art of data science and AI.\n",
        "\"\"\"\n",
        "\n",
        "# 2. PREPROCESSING\n",
        "text = data.lower()\n",
        "words = text.split()\n",
        "vocab = sorted(list(set(words)))\n",
        "word_to_idx = {word: i for i, word in enumerate(vocab)}\n",
        "idx_to_word = {i: word for i, word in enumerate(vocab)}\n",
        "vocab_size = len(vocab)\n",
        "\n",
        "# Create input sequences (N-Grams)\n",
        "input_sequences = []\n",
        "for i in range(1, len(words)):\n",
        "    n_gram = words[:i+1]\n",
        "    input_sequences.append([word_to_idx[w] for w in n_gram])\n",
        "\n",
        "# Padding\n",
        "max_len = max([len(seq) for seq in input_sequences])\n",
        "padded_sequences = np.array([([0] * (max_len - len(seq)) + seq) for seq in input_sequences])\n",
        "\n",
        "# Split into Features (X) and Label (y)\n",
        "X = torch.tensor(padded_sequences[:, :-1], dtype=torch.long)\n",
        "y = torch.tensor(padded_sequences[:, -1], dtype=torch.long)\n",
        "\n",
        "# 3. MODEL ARCHITECTURE\n",
        "class LSTMModel(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim):\n",
        "        super(LSTMModel, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embedded = self.embedding(x)\n",
        "        lstm_out, (h, c) = self.lstm(embedded)\n",
        "        # Use the hidden state of the last time step\n",
        "        logits = self.fc(lstm_out[:, -1, :])\n",
        "        return logits\n",
        "\n",
        "# Initialize Model\n",
        "EMBED_DIM = 100\n",
        "HIDDEN_DIM = 150\n",
        "model = LSTMModel(vocab_size, EMBED_DIM, HIDDEN_DIM)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
        "\n",
        "# 4. TRAINING LOOP\n",
        "print(\"--- Starting Training ---\")\n",
        "for epoch in range(100):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    output = model(X)\n",
        "    loss = criterion(output, y)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if (epoch + 1) % 20 == 0:\n",
        "        print(f\"Epoch {epoch+1}/100 | Loss: {loss.item():.4f}\")\n",
        "\n",
        "# 5. PREDICTION FUNCTION\n",
        "def predict_next_words(seed_text, next_words=5):\n",
        "    model.eval()\n",
        "    for _ in range(next_words):\n",
        "        # Tokenize and pad the input\n",
        "        words_in_seed = seed_text.lower().split()\n",
        "        tokens = [word_to_idx[w] for w in words_in_seed if w in word_to_idx]\n",
        "\n",
        "        if not tokens: break # Handle unknown words\n",
        "\n",
        "        # Pad sequence to match max_len-1\n",
        "        padded_tokens = [0] * (max_len - 1 - len(tokens)) + tokens\n",
        "        input_tensor = torch.tensor([padded_tokens], dtype=torch.long)\n",
        "\n",
        "        # Get prediction\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            next_word_idx = torch.argmax(output, dim=1).item()\n",
        "            next_word = idx_to_word[next_word_idx]\n",
        "\n",
        "        seed_text += \" \" + next_word\n",
        "    return seed_text\n",
        "\n",
        "# 6. TEST IT\n",
        "print(\"\\n--- Testing Model ---\")\n",
        "test_sentence = \"What is\"\n",
        "prediction = predict_next_words(test_sentence, next_words=20)\n",
        "print(f\"Input: '{test_sentence}'\\nOutput: '{prediction}'\")"
      ]
    }
  ]
}